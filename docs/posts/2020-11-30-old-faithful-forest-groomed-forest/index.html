<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>My Blog: Old faithful, Meet the Neighbors, and Lost in the Forest</title>

<meta property="description" itemprop="description" content="Model description and evaluation."/>


<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-11-30"/>
<meta property="article:created" itemprop="dateCreated" content="2020-11-30"/>
<meta name="article:author" content="Shaina Trevino, Jonathan Pedroza, Akhila Nekkanti"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="My Blog: Old faithful, Meet the Neighbors, and Lost in the Forest"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Model description and evaluation."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="My Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary"/>
<meta property="twitter:title" content="My Blog: Old faithful, Meet the Neighbors, and Lost in the Forest"/>
<meta property="twitter:description" content="Model description and evaluation."/>

<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output"]}},"value":[{"type":"character","attributes":{},"value":["Old faithful, Meet the Neighbors, and Lost in the Forest"]},{"type":"character","attributes":{},"value":["Model description and evaluation."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Shaina Trevino, Jonathan Pedroza, Akhila Nekkanti"]},{"type":"character","attributes":{},"value":["https://github.com/akhilanekkanti1/Final_ML_Blog"]}]}]},{"type":"character","attributes":{},"value":["11-30-2020"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["model1-lr.Rds","model2-knn.Rds","old-faithful-forest-groomed-forest_files/anchor-4.2.2/anchor.min.js","old-faithful-forest-groomed-forest_files/bowser-1.9.3/bowser.min.js","old-faithful-forest-groomed-forest_files/distill-2.2.21/template.v2.js","old-faithful-forest-groomed-forest_files/figure-html5/unnamed-chunk-14-1.png","old-faithful-forest-groomed-forest_files/jquery-1.11.3/jquery.min.js","old-faithful-forest-groomed-forest_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #455a64;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative;}
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for table of contents */

.d-toc {
  color: rgba(0,0,0,0.8);
  font-size: 0.8em;
  line-height: 1em;
}

.d-toc-header {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  text-transform: uppercase;
  margin-top: 0;
  margin-bottom: 1.3em;
}

.d-toc a {
  border-bottom: none;
}

.d-toc ul {
  padding-left: 0;
}

.d-toc li>ul {
  padding-top: 0.8em;
  padding-left: 16px;
  margin-bottom: 0.6em;
}

.d-toc ul,
.d-toc li {
  list-style-type: none;
}

.d-toc li {
  margin-bottom: 0.9em;
}

.d-toc-separator {
  margin-top: 20px;
  margin-bottom: 2em;
}

.d-article-with-toc {
  border-top: none;
  padding-top: 0;
}



/* Tweak code blocks (note that this CSS is repeated above in an injection
   into the d-code shadow dom) */

d-code {
  overflow-x: auto !important;
}

pre.d-code code.d-code {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

pre.text-output {

  font-size: 12px;
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

@media(min-width: 768px) {

d-code {
  overflow-x: visible !important;
}

pre.d-code code.d-code  {
    padding-left: 18px;
    font-size: 14px;
}
pre.text-output {
  font-size: 14px;
}
}

/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}



/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}


/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // create d-bibliography
  var bibliography = $('<d-bibliography></d-bibliography>');
  $('#distill-bibliography').wrap(bibliography);

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace citations with <d-cite>
  $('.citation').each(function(i, val) {
    appendix = true;
    var cites = $(this).attr('data-cites').split(" ");
    var dt_cite = $('<d-cite></d-cite>');
    dt_cite.attr('key', cites.join());
    $(this).replaceWith(dt_cite);
  });
  // remove refs
  $('#refs').remove();

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-toc a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // replace code blocks with d-code
  $('pre>code').each(function(i, val) {
    var code = $(this);
    var pre = code.parent();
    var clz = "";
    var language = pre.attr('class');
    if (language) {
      // map unknown languages to "clike" (without this they just dissapear)
      if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                               "javascript", "js", "julia", "lua", "markdown",
                               "markup", "mathml", "python", "svg", "xml"]) == -1)
        language = "clike";
      language = ' language="' + language + '"';
      var dt_code = $('<d-code block' + language + clz + '></d-code>');
      dt_code.text(code.text());
      pre.replaceWith(dt_code);
    } else {
      code.addClass('text-output').unwrap().changeElementType('pre');
    }
  });

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('d-code, pre.text-output, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // table of contents
    if (have_authors) // adjust border if we are in authors
      $('.d-toc').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
    $('d-code').each(function(i, val) {
      var style = document.createElement('style');
      style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                        '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
      if (this.shadowRoot)
        this.shadowRoot.appendChild(style);
    });

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-toc-header').remove();
  $('.d-toc').remove();
  $('.d-toc-separator').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Old faithful, Meet the Neighbors, and Lost in the Forest","description":"Model description and evaluation.","authors":[{"author":"Shaina Trevino, Jonathan Pedroza, Akhila Nekkanti","authorURL":"https://github.com/akhilanekkanti1/Final_ML_Blog","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2020-11-30T00:00:00.000-08:00","citationText":"Nekkanti, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="../../index.html" class="title">My Blog</a>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../about.html">About</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Old faithful, Meet the Neighbors, and Lost in the Forest</h1>
<p><p>Model description and evaluation.</p></p>
</div>

<div class="d-byline">
  Shaina Trevino, Jonathan Pedroza, Akhila Nekkanti <a href="https://github.com/akhilanekkanti1/Final_ML_Blog" class="uri">https://github.com/akhilanekkanti1/Final_ML_Blog</a> 
  
<br/>11-30-2020
</div>

<div class="d-article">
<h1 id="overview">Overview</h1>
<p>In this post we are going to describe our process for the three machine learning models that we ran (e.g., penalized regression, k-nearest neighbor, random forest) and compare the performance of all models. The results that are presented are from the full dataset described in the previous post. <a href="https://akhilanekkanti1.github.io/Final_ML_Blog/posts/2020-11-30-shoe-me-what-youre-working-with-data-desc/">Check it out here.</a>. Since the full dataset was so large, we utilized a High Performance Computing (HPC) cluster from the University of Oregon (Talapas) to run all models.</p>
<h2 id="split-the-data">Split the Data</h2>
<p>Before we start fitting models, the first step is to split our data into two parts: training and testing data. To do this, we use <code>initial_split</code> to split the data and then define our training and testing set. Notice that we also used stratified sampling (<code>strata = "score"</code>) when splitting our data to ensure the training and testing sets have similar outcome responses.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(1272020)

d_split &lt;- initial_split(d, strata = &quot;score&quot;)

d_train &lt;- training(d_split)
d_test  &lt;- testing(d_split)</code></pre>
</div>
<p>Then, we take our testing set and create a k-fold cross validation object. This splits our training set into 10 different samples of data each with their own training and testing set. We will use this object to evaluate the performance metrics for each model across all 10 samples.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(1272020)

train_cv &lt;- vfold_cv(d_train, strata = &quot;score&quot;)</code></pre>
</div>
<h2 id="define-the-recipe">Define the Recipe</h2>
<p>This recipe is explained in the previous post. However, we provided the code here as well for completeness. We will use this same recipe for all models.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
rec_yoself &lt;- recipe(score ~ .,data = d_train) %&gt;%
  step_mutate(tst_dt = as.numeric(lubridate::mdy_hms(tst_dt))) %&gt;% 
  update_role(contains(&quot;id&quot;), ncessch, new_role = &quot;id vars&quot;) %&gt;%
  step_unknown(all_nominal()) %&gt;% 
  step_novel(all_nominal()) %&gt;% 
  step_dummy(all_nominal()) %&gt;% 
  step_nzv(all_predictors()) %&gt;%
  step_normalize(all_numeric(), -all_outcomes(), -has_role(&quot;id vars&quot;)) %&gt;%
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role(&quot;id vars&quot;)) %&gt;%  
  step_interact(terms = ~lat:lon) %&gt;% 
  step_nzv(all_predictors())</code></pre>
</div>
<h1 id="model-1-old-faithful---penalized-regression-model">Model 1: Old Faithful - Penalized Regression Model</h1>
<p>Finally, we are ready to create our first model. This will be a penalized regression, specifically an elastic net model. Linear regression models are usually easier to interpret and less computationally intensive.</p>
<p>To run an enet model, you must specify the penalty argument (for dealing with multicolinearity) and the mixture argument (proportion of ridge [0] to lasso [1] models). For our purposes, we will tune these parameters to find the values that result in the best model performance.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
lr_mod &lt;- linear_reg()  %&gt;%
  set_engine(&quot;glmnet&quot;) %&gt;% 
  set_mode(&quot;regression&quot;) %&gt;% 
  set_args(penalty = tune(),
           mixture = tune())</code></pre>
</div>
<h4 id="workflow">Workflow</h4>
<p>After specifying our enet model, we use the <code>workflow</code> package to combine our recipe and our model into one workflow object. This makes it easier to monitor and update your recipe and model that you are working with.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
lr_flo &lt;- workflow() %&gt;% 
  add_recipe(rec_yoself) %&gt;% 
  add_model(lr_mod)</code></pre>
</div>
<h4 id="tune-model">Tune Model</h4>
<p>We are now ready to tune our enet model. To tune the model we first need to create a grid for tuning parameters. Since we are using a linear regression model, we decided to use a regular grid with our two hyperparameters (<code>penalty()</code> and <code>mixture()</code>). We also specified 30 levels (i.e., 30 values for each hyperparameter) to create the grid.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#create grid
lr_grd &lt;- grid_regular(penalty(), mixture(), levels = 30)

#tune model 
tictoc::tic()
lr_res &lt;- tune::tune_grid(lr_flo, resamples = train_cv, grid = lr_grd,
                           control = tune::control_resamples(save_pred = TRUE))
tictoc::toc()</code></pre>
</div>
<p>When we ran the previous model on the HPC cluster, it only took 26 minutes to tune. The values that lead to the highest performance (i.e., lowest RMSE) for our tuning parameters were:</p>
<ul>
<li><p>Penalty = &lt;0.00</p></li>
<li><p>Mixture = 0.03</p></li>
</ul>
<p>Note: Because both values are so low, we would expect to get very similar results with a ridge regression model and it would be less computationally intensive.</p>
<h4 id="apply-best-tuning-parameters">Apply Best Tuning Parameters</h4>
<p>We can then apply these values to our arguments in our model with the <code>select_best</code> function. Remember to update and finalize your workflow with the new model as well.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#select best tuning parameters
lr_best &lt;- lr_res %&gt;% 
  select_best(metric = &quot;rmse&quot;)

#finalize model in workflow
lr_flo_final &lt;- finalize_workflow(lr_flo, lr_best)</code></pre>
</div>
<h3 id="model-1-results">Model 1 Results</h3>
<p>Once we have finalized our model and workflow, we can use the <code>last_fit()</code> function to apply our recipe and model to the <code>initial_split</code> object we made. This will evaluate the model performance on the testing set. We then use the <code>collect_metrics()</code> function to view our performance metrics on the test set.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#evaluate on test set with last_fit
lr_final_res &lt;- last_fit(
  lr_flo_final,
  split = d_split)

#view performance metric
lr_final_res %&gt;%
  collect_metrics() %&gt;% 
  filter(`.metric` == &quot;rmse&quot;)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>
# A tibble: 1 x 4
  .metric .estimator .estimate .config             
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;fct&gt;               
1 rmse    standard        89.0 Preprocessor1_Model1</code></pre>
</div>
<p>As you can see, our final performance metric (RMSE) for our penalized regression model is <code>89.03</code>.</p>
<h4 id="get-predictions">Get Predictions</h4>
<p>We also wanted to note that if you wanted to extract predictions from the test dataset within the split object (e.g., <code>d_split</code>), you can use the <code>collect_predictions()</code> function.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
test_preds &lt;- lr_final_res %&gt;% collect_predictions()
test_preds</code></pre>
</div>
<h1 id="model-2-meet-the-neighbors---k-nearest-neighbor-knn-an">Model 2: Meet the Neighbors - K Nearest Neighbor (KNN) (AN)</h1>
<h4 id="well-use-the-same-data-and-recipe-from-our-first-model---this-way-we-can-see-whether-improvements-to-model-fit-are-actually-due-to-an-improved-model.">We’ll use the same data and recipe from our first Model - This way, we can see whether improvements to model fit are actually due to an improved model.</h4>
<h5 id="a-k-nearest-neighbor-knn-model-aims-to-find-the-closest-neighbors-or-closest-data-points-in-the-predictor-space.-this-means-that-the-model-uses-information-from-previous-samples-to-find-the-points-that-are-closest-in-proximity-to-the-new-sample.-while-knn-models-can-be-computationally-inefficient-they-make-fewer-assumptions-about-the-data-and-may-be-preferable-when-datasets-are-nonparametric-or-where-distributions-are-largely-unknown.-we-chose-this-model-for-our-case-because-many-of-our-predictors-are-non-parametric-and-our-dataset-is-very-large.">A K nearest neighbor (KNN) model aims to find the closest <em>neighbors</em>, or closest data points in the predictor space. This means that the model uses information from previous samples to find the points that are closest in proximity to the new sample. While KNN models can be computationally inefficient, they make fewer assumptions about the data and may be preferable when datasets are nonparametric, or where distributions are largely unknown. We chose this model for our case because many of our predictors are non-parametric and our dataset is very large.</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
knn_mod &lt;- nearest_neighbor()  %&gt;%
  set_engine(&quot;kknn&quot;) %&gt;% </code></pre>
</div>
<h5 id="when-specifying-the-model-we-set-the-mode-to-regression.-this-tells-it-to-take-the-average-outcome-of-k-cases-rather-than-the-mode.-because-our-outcome-is-continuous-we-went-with-the-regression-method.">When specifying the model, we set the mode to “regression”. This tells it to take the average outcome of <em>K</em> cases, rather than the mode. Because our outcome is continuous, we went with the regression method.</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#knn_mod &lt;- nearest_neighbor()  %&gt;%
#  set_engine(&quot;kknn&quot;) %&gt;% 
  set_mode(&quot;regression&quot;) %&gt;%</code></pre>
</div>
<h4 id="next-we-determine-how-to-identify-the-neighbors.-the-defaults-from-the-kknn-package-include-5-neighbors-set-the-weight_func-to-optimal-and-the-dist_power-to-2.">Next we determine how to identify the neighbors. The defaults from the <code>{kknn}</code> package include 5 neighbors, set the <code>weight_func</code> to “optimal”, and the <code>dist_power()</code> to “2”.</h4>
<ul>
<li><p>If K is small (e.g., 1), there is greater potential for over-fitting as it is more susceptible to changes in the data (think low bias but high variance). Larger values of K means the model will be looking at potentially irrelevant data points. This can be helpgul when data are noisy, but not always. Think high bias, and low variance.</p></li>
<li><p>The weight_func determines how to weight the distances between samples. In other words, it determines whether or not to penalize for a point being farther away.</p></li>
<li><p>The dist_power function specifies how far points should be.</p></li>
</ul>
<h5 id="here-we-set-each-of-these-parameters-to-tune-so-that-the-model-could-determine-the-best-values-based-on-the-data.">Here, we set each of these parameters to ‘tune()’, so that the model could determine the best values based on the data.</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#knn_mod &lt;- nearest_neighbor()  %&gt;%
#  set_engine(&quot;kknn&quot;) %&gt;% 
#  set_mode(&quot;regression&quot;) %&gt;% 
  set_args(neighbors = tune()),
           weight_func = tune(),
           dist_power = tune())</code></pre>
</div>
<h5 id="unfortunately-setting-all-three-parameters-to-tune-was-computationally-inefficient.-that-is-it-took-longer-than-16-hours-to-run-on-a-cluster-computer.-so-we-removed-the-tuning-parameters-for-weight_func-and-dist_power-and-left-these-to-the-defaults.-we-felt-it-was-important-to-tune-the-neighbors-however.">Unfortunately, setting all three parameters to ‘tune()’ was computationally inefficient. That is, it took longer than 16 hours to run on a cluster computer. So, we removed the tuning parameters for ‘weight_func’ and ‘dist_power’, and left these to the defaults. We felt it was important to tune the neighbors however.</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
knn_mod &lt;- nearest_neighbor()  %&gt;%
  set_engine(&quot;kknn&quot;) %&gt;% 
  set_mode(&quot;regression&quot;) %&gt;% 
  set_args(neighbors = tune())#,
           #weight_func = tune()#,
           #dist_power = tune())</code></pre>
</div>
<h5 id="woohoo-model-specified-now-to-create-a-workflow-and-start-running-things.-here-we-use-a-workflow-to-bundle-our-preprocessing-and-modelling-together.-were-using-the-same-recipe-as-before-rec_yoself-and-the-model-we-just-created-knn_mod.">Woohoo! Model = specified! Now to create a workflow and start running things. Here we use a workflow to bundle our preprocessing and modelling together. We’re using the same recipe as before, ‘rec_yoself’, and the model we just created, ‘knn_mod’.</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
knn_flo &lt;- lr_flo %&gt;% 
  update_model(knn_mod)</code></pre>
</div>
<h5 id="we-aimed-to-use-a-space-filling-design-when-specifying-our-non-regular-grid.-this-type-of-design-aims-to-keep-potential-points-away-from-each-other-while-also-encompassing-the-entire-parameter-space.-here-we-specify-the-parameters-as-well-as-the-range-for-neighbors-prior-to-creating-the-grid.-note---this-is-prior-to-removing-the-tuning-parameters-above">We aimed to use a space-filling design when specifying our non-regular grid. This type of design aims to keep potential points away from each other while also encompassing the entire parameter space. Here, we specify the parameters, as well as the range for neighbors, prior to creating the grid. (*Note - this is prior to removing the tuning parameters above)</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
knn_par &lt;- parameters(neighbors(range = (c(10, 75))), weight_func(), dist_power()) #testing with smaller range due to computation
knn_grd &lt;- grid_max_entropy(knn_par, size = 30)</code></pre>
</div>
<h5 id="unfortunately-this-too-contributed-to-a-computationally-inefficient-model.-so-we-used-the-defaults-for-grid_max_entropy-and-only-specified-neighbors-and-size-of-the-grid.">Unfortunately, this too contributed to a computationally inefficient model. So, we used the defaults for <code>grid_max_entropy()</code> and only specified <code>neighbors()</code> and size of the grid.</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#knn_par &lt;- parameters(neighbors(range = (c(10, 75))), weight_func(), dist_power()) #testing with smaller range due to computation
knn_grd &lt;- grid_max_entropy(neighbors(), size = 30) #testing with smaller size due to computation </code></pre>
</div>
<h5 id="finally-we-are-ready-to-tune-our-grid-according-to-our-cross-fold-validated-data.-we-specify-our-workflow-knn_flo-the-resamples-we-want-the-model-to-use-train_cv-and-the-grid-we-created-above-knn_grd.">Finally, we are ready to tune our grid according to our cross-fold validated data. We specify our workflow (knn_flo), the resamples we want the model to use (train_cv), and the grid we created above (knn_grd).</h5>
<h5 id="youll-notice-in-between-the-hashtags-we-include-some-code-to-employ-parallel-processing.-this-allows-the-model-to-run-on-each-sample-simultaneously-in-an-attempt-to-cut-down-on-computation-time.">You’ll notice in between the hashtags, we include some code to employ parallel processing. This allows the model to run on each sample simultaneously, in an attempt to cut down on computation time.</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
#
cl &lt;- makePSOCKcluster(all_cores)
registerDoParallel(cl)
foreach::getDoParWorkers()
clusterEvalQ(cl, {library(tidymodels)})
#

knn_res &lt;- tune::tune_grid(knn_flo, resamples = train_cv, grid = knn_grd,
                           control = tune::control_resamples(save_pred = TRUE))

#
parallel::stopCluster(cl)
#</code></pre>
</div>
<h5 id="lastly-we-want-to-select-the-best-tuning-parameters-and-use-them-to-finalize-the-workflow.-as-you-may-have-guessed-the-only-tuned-parameters-are-the-number-of-neighbors---since-both-the-dist_func-and-weight_func-were-too-computationally-expensive-to-move-away-from-defaults.-the-optimal-number-of-neighbors-for-our-model-was-10.">Lastly, we want to select the best tuning parameters and use them to finalize the workflow. As you may have guessed, the only tuned parameters are the number of neighbors - since both the dist_func and weight_func were too computationally expensive to move away from defaults. The optimal number of neighbors for our model was <code>10</code>.</h5>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
knn_best &lt;- knn_res %&gt;% 
  select_best(metric = &quot;rmse&quot;)

knn_flo_final &lt;- finalize_workflow(knn_flo, knn_best)

registerDoSEQ() 
knn_final_res &lt;- last_fit(
  knn_flo_final,
  split = d_split)

knn_final_res %&gt;%
  collect_metrics()</code></pre>
</div>
<h5 id="since-we-ran-our-model-on-the-hpc-we-are-reading-in-our-model-first.">Since we ran our model on the HPC, we are reading in our model first.</h5>
<div class="layout-chunk" data-layout="l-body">

</div>
<h5 id="our-final-performance-metric-rmse-for-our-knn-regression-model-is-92.20.-yikes-this-metric-is-not-so-great-but-our-total-elapsed-time-of-1772.517-seconds-on-a-cluster-computer-is-pretty-amazing.-the-high-rmse-may-be-due-to-our-leaving-in-the-defaults-for-dist_power-and-weight_func-when-tuning-our-model.-next-steps-if-time-allowed-would-include-tuning-just-the-weight_func-and-specifying-a-value-for-dist_power-based-on-the-manhattan-measure-since-most-of-our-predictors-are-categorical.">Our final performance metric (RMSE) for our KNN regression model is <code>92.20</code>. Yikes! This metric is not so great, but our total elapsed time of 1772.517 seconds on a cluster computer is pretty amazing. The high RMSE may be due to our leaving in the defaults for <code>dist_power()</code> and <code>weight_func</code> when tuning our model. Next steps, if time allowed, would include tuning just the <code>weight_func</code>, and specifying a value for <code>dist_power</code> based on the Manhattan measure (since most of our predictors are categorical).</h5>
<h1 id="model-3-lost-in-the-forest---random-forest-jp">Model 3: Lost in the Forest - Random Forest (JP)</h1>
<p>Okay, so we’ve tested a elastic net regression and a KNN model. We’ve seen how simple to implement the elastic net regression was and we’ve experienced the waiting game of running a KNN model. <img src="https://media.giphy.com/media/9SIXFu7bIUYHhFc19G/giphy.gif" alt="well were waiting" /></p>
<p>Let’s move on to our final model, a random forest model. Now, what is a random forest model? Random forest stems (ha!) from a decision tree but rather than have one tree, we will have 1000 trees.</p>
<figure>
<img src="https://media.giphy.com/media/RbDxrcG2deKnm/giphy.gif" alt="Charlie brown" /><figcaption>Charlie brown</figcaption>
</figure>
<p>Random forest is also different from bagged trees because while there are multiple trees, bagged trees aggregates the predictions across all trees and has the issue of correlations between the nodes for trees. So random forest reduces correlations between trees by making sure trees are different from one another by including randomness at each split in the tree. Random forest was also chosen over bagged trees because it is faster, although it might not feel like it based on our final plot. The two hyper-parameters that were tuned for our random forest model were the <code>mtry</code> and the <code>min_n</code> parameters. Mtry is important because it is the main parameter of dealing with tree correlation by making sure the predictors chosen for the root nodes are different each time rather than only picking a handful of predictors as the root node. Min_n is important because this parameter decides whether or not the node splits further to make deeper trees. While not tuned, the number of trees was set to 1000 rather than the default of 500. From this model, we will be able to see which nodes are the most important predictors for students’ scores. Lastly, model performance will be assessed by RMSE to compare to the other two models’ performance.</p>
<p>When creating a random forest model, there are some additional arguments that are needed. First, it is important to use as many cores on your local computer as you can so you’re not waiting for forever while this model runs. The permutation argument is important for splitting and considers any variable important if it makes the predictive accuracy better and repeats it for each predictor.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
(cores &lt;- parallel::detectCores())

model_of_forests &lt;- rand_forest() %&gt;%
set_engine(&quot;ranger&quot;,
num.threads = cores, #
importance = &quot;permutation&quot;, 
verbose = TRUE) %&gt;% 
set_mode(&quot;regression&quot;) %&gt;% 
  set_args(mtry = tune(),
           trees = 1000,
           min_n = tune())</code></pre>
</div>
<p>Next, we’ll update our existing workflow object to examine the random forest model in the previous code chunk. Now that we have our workflow created, we can then run the model and recipe to get the best RMSE value. We also set the grid to 10 to get 10 values of our hyper-parameters.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
forest_flo &lt;- knn_flo %&gt;%
update_model(model_of_forests)

tictoc::tic()
tune_random_trees &lt;- tune_grid(
    forest_flo,
    resamples = train_cv,
    grid = 10,
    metrics = metric_set(rmse),
    control = control_resamples(verbose = TRUE, 
                               save_pred = TRUE, 
                               extract = function(x) x)) 
tictoc::toc()

train_best &lt;- select_best(tune_random_trees, metric = &quot;rmse&quot;)</code></pre>
</div>
<p>Now that we have the best values for our hyper-parameters and have our RMSE, we can then finalize our workflow and run the last_fit to see how the random forest performed.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train_wf_final &lt;- finalize_workflow(
  forest_flo,
  train_best
)

tictoc::tic()
train_res_final &lt;- last_fit(train_wf_final,
                            split = d_split)
tictoc::toc()

train_res_final %&gt;% 
  collect_metrics()</code></pre>
</div>
<h2 id="model-fits">Model Fits</h2>
<p>Now that we have examined all three different models using a small percentage of the actual data, we can discuss which model fits the data best. While it may be different for based on using a small percentage, if you happen to have a supercomputer, you can analyze the full dataset. In the following code chunk, we gathered information about the RMSE, which is the fit metric we are using, the amount of time it took to run the model with all the data, and the name of the model. We can see that the best fitting model is the random forest.</p>
<figure>
<img src="https://media.giphy.com/media/ndOEKTqUOEPq8/giphy.gif" alt="best tree" /><figcaption>best tree</figcaption>
</figure>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model_metrics &lt;- tibble(&#39;model&#39; = c(&#39;Elastic Net Regression&#39;, &#39;KNN&#39;, &#39;Random Forest&#39;),
                           &#39;time&#39; = c(1552.90, 1772.52, 13919.06),
                           &#39;rmse&#39; = c(89.02, 92.20, 85.50))

ggplot(model_metrics, aes(time, rmse)) +
  geom_line() +
  geom_point(aes(color = model), size = 2.5) +
  xlim(0, 15000) +
  annotate(&quot;text&quot;, x = 1400, y = 88.55, label = &quot;Elastic Net&quot;, size = 5, color = &#39;#12D7AD&#39;) +
  annotate(&quot;text&quot;, x = 2800, y = 92.30, label = &quot;KNN*&quot;, size = 5, color = &#39;#127AD7&#39;) +
  annotate(&quot;text&quot;, x = 13500, y = 88.5, label = &quot;Random Forest \n mtry = 5 \n min_n = 40 \n trees = 1000&quot;, size = 5, color = &#39;#D7126D&#39;) +
  labs(title = &#39;Comparison of RMSE of three models fit&#39;,
       subtitle = &#39;Testing dataset predictions&#39;,
       y = &#39;RMSE&#39;,
       caption = &quot;* = KNN model did not tune all hyperparameters due to computation time\n Computations were conducted on the UO&#39;s Talapas &quot;) +
  theme_minimal() +
  theme(legend.position = &quot;none&quot;) +
  scale_color_manual(values = c(&#39;#12D7AD&#39;, &#39;#127AD7&#39;, &#39;#D7126D&#39;))</code></pre>
<p><img src="old-faithful-forest-groomed-forest_files/figure-html5/unnamed-chunk-14-1.png" width="624" /></p>
</div>
<p>However, it is important to note that while the random forest model was the best performing model, it also took substantially longer to run. This was also a determining factor in how many parameters we could tune in the KNN model, as it was computationally exhausting to run. Overall, the random forest was enough of a better performing model that we think it was best to run that over a penalized regression model. While feature engineering changes could have probably resulted in a better fitting model for all three, this blog was to compare the models with the same recipe. So if you decide to fit these three models, some takeaways are:</p>
<ol type="1">
<li><p>Feature engineering is an important to step to get the most out of your models. It also helps if you have background information regarding the data you are working with.</p></li>
<li><p>Think about the pros and cons of a better performing model and the time it takes to run the model.</p></li>
<li><p>Experiment with other models not shown here.</p></li>
<li><p>Try to find as much relevant data as possible to help in predicting your outcome of interest.</p></li>
</ol>
<div class="layout-chunk" data-layout="l-body">

</div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
